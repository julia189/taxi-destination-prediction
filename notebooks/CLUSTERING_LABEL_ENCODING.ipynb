{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cbb67f",
   "metadata": {},
   "source": [
    "1) Multi-regression output problem --> predict two labels: longitude and latitude\n",
    "\n",
    "2) Re-write problem as multi-class problem through clustering\n",
    "To define the classes, the last points per trip from the training data will be divided into clusters. When we have a large enough number of clusters, the clusters should be small enough to have their points close to their centroids. \n",
    "\n",
    "K-Means is a good approach as it minimizes the sum of squared distances within the cluster. Also it scales well to a large number of clusters. \n",
    "\n",
    "So the approach then predicts: **Probability of final destination of a trip being located in a specific cluster**\n",
    "\n",
    "Steps:\n",
    "- Get optimal number of clusters with help of interia\n",
    "- Generate clusters with K-Means for each trip in training data\n",
    "- Predict cluster for each trip in testing data\n",
    "- Get centroids for each cluster \n",
    "- Calculate distance from points in cluster to centroid to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883f9d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import awswrangler as wr\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "import dask.array as da\n",
    "from dask_ml import cluster\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a5d153-9da9-4847-9cbe-c03e916f8aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_sagemaker_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d63b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_sagemaker_notebook:\n",
    "    prefix = \"/home/ec2-user/SageMaker\"\n",
    "else:\n",
    "    prefix = \"/Users/Q619505/PycharmProjects/personal-projects\"\n",
    "\n",
    "utils_path = os.path.join(f'{prefix}/ml-project-taxi-prediction/src/utils/')\n",
    "pp_path = os.path.join(f'{prefix}/ml-project-taxi-prediction/src/preprocessing')\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "if pp_path not in sys.path:\n",
    "    sys.path.append(pp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73853fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extract_lat_lon' from 'geo_spatial' (/Users/Q619505/PycharmProjects/personal-projects/ml-project-taxi-prediction/src/preprocessing/geo_spatial.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeo_spatial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_polyline_to_geojson_format, extract_lat_lon\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extract_lat_lon' from 'geo_spatial' (/Users/Q619505/PycharmProjects/personal-projects/ml-project-taxi-prediction/src/preprocessing/geo_spatial.py)"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from geo_spatial import convert_polyline_to_geojson_format, extract_lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612d9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/test_data.csv')\n",
    "train_data = pd.read_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175aa35f-9fb8-4a9b-b78c-250e866b0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_polyline_to_geojson_format(data=train_data, name_column='dest_point')\n",
    "test_data = convert_polyline_to_geojson_format(data=test_data, name_column='dest_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7758bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = extract_lat_lon(train_data,'start_point')\n",
    "test_data = extract_lat_lon(test_data,'start_point')\n",
    "\n",
    "train_data = extract_lat_lon(train_data,'dest_point')\n",
    "test_data = extract_lat_lon(test_data,'dest_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91865d31",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.vstack(train_data.dest_point)\n",
    "# transform destintion point to dask format\n",
    "X_da = da.from_array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651170a-fa13-41f1-bb9e-dcb595a39951",
   "metadata": {},
   "source": [
    "- Inertia/sum of squared distance shows still significant reduction for 4000 clusters, therefore choose n_clusters = 4000\n",
    "- Due to high execution time more iterations are not considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67014015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inertia_per_k = [(k, KMeans(n_clusters=k, init='k-means++', verbose=True, random_state=1).fit(X_da).inertia_)\n",
    "#  for k in range(1000,5000,1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866260be-69fa-429a-9501-3ece308bcf57",
   "metadata": {},
   "source": [
    "One iteration is sufficient as single points need to be clustered, the nature of the data already provides the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e134c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a745a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('clustering', KMeans(n_clusters = 4000,\n",
    "                                       init ='k-means++',\n",
    "                                       n_init = 1, \n",
    "                                       verbose=True,\n",
    "                                       random_state=1\n",
    "                                      )\n",
    "                 )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971b746",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_label = pipe.fit_predict(X_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d38735-44ed-4cd8-a41f-b3957cdf8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cluster_label']=cluster_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c472-e63f-4dc9-b55f-504c8786891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_scaled = pipe[1].cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b8546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers = pipe[0].inverse_transform(centers_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f297593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers = pd.DataFrame(centers, columns=['CENTER_LON','CENTER_LAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d4aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers = centers.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1accd1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(train_data.cluster_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e0fdf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.vstack(test_data.dest_point)\n",
    "X_da_test = da.from_array(np.array(X_test))\n",
    "cluster_label = pipe.predict(X_da_test)\n",
    "test_data['cluster_label']=cluster_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fecefd-448d-452b-be16-4b06630beb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(test_data.cluster_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7818346-b7c1-418c-938f-39e503aa2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(centers.index.max() == train_data.cluster_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac51df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.merge(test_data, centers[['index','center_lon','center_lat']], \n",
    "                           how='left', \n",
    "                           left_on='cluster_label',\n",
    "                           right_on='index')\n",
    "train_data = pd.merge(train_data, centers[['index','center_lon','center_lat']], \n",
    "                           how='left', \n",
    "                           left_on='cluster_label',\n",
    "                           right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833cad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cluster = train_data.cluster_label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4a801-084d-4c7b-9e78-5cf946e9ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_sagemaker_notebook:\n",
    "    aw.s3.to_parquet(df=train_data, path=f's3://think-tank-casestudy/preprocessed_data/n_cluster_{n_cluster}/train_data_clustered.parquet', dataset=True, partition_cols=['taxi_id'])\n",
    "    aw.s3.to_parquet(df=test_data, path=f's3://think-tank-casestudy/preprocessed_data/n_cluster_{n_cluster}/test_data_clustered.parquet', dataset=True, partition_cols=['taxi_id'])\n",
    "\n",
    "else:\n",
    "    train_data.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/train_data_clustered.csv', header=True, index=False)\n",
    "    test_data.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/test_data_clustered.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxi-prediction",
   "language": "python",
   "name": "taxi-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
