{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd861eb",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c903b",
   "metadata": {},
   "source": [
    "The filtered, calculated and encoded features can now be trained with appropriate models.\n",
    "\n",
    "The following approaches are considered:\n",
    "- Multi classification problem with clustered data\n",
    "- Mutli regression problem with two outputs (longitude/latitude)\n",
    "\n",
    "In terms of the data we have the following approaches:\n",
    "- variable sequence length - can take all points in POLYLINE in consideration, mask sequence if necessary\n",
    "- fixed sequence length - take 10 points from beginning of POLYLINE and 10 points from end of polyline \n",
    "\n",
    "\n",
    "Algorithms:\n",
    "- Long term short term NN (multi-class classification and regression)\n",
    "    - able to handle variable sequence length, therefore the total trip POLYLINE can be used\n",
    "- Random forest(regression and classification) \n",
    "    - can handle outliers well as dataset still contains outliers\n",
    "    - runs efficiently on large data set\n",
    "    \n",
    "Metrics:\n",
    "- Classification of clusters: AUC + Avg distance of last point to cluster center\n",
    "- Regression: MAPE + Avg distance of last point to cluster center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e88351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab5fc67-d05b-4a39-a3ab-cd55c95624ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_sagemaker_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306084de-8bb1-42a1-9ef8-145b0fbdd68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_sagemaker_notebook:\n",
    "    prefix = \"/home/ec2-user/SageMaker\"\n",
    "else:\n",
    "        prefix = \"/Users/Q619505/PycharmProjects/personal-projects/taxi-destination-prediction\"\n",
    "\n",
    "utils_path = os.path.join(f'{prefix}/src/utils/')\n",
    "pp_path = os.path.join(f'{prefix}/src/preprocessing/')\n",
    "model_path = os.path.join(f'{prefix}/src/modelling/')\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "if pp_path not in sys.path:\n",
    "    sys.path.append(pp_path)\n",
    "\n",
    "if model_path not in sys.path:\n",
    "    sys.path.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623fa49c-2915-4d45-aade-ac75ea00716d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeo_spatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/personal-projects/taxi-destination-prediction/src/modelling/model.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultioutput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiOutputRegressor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Input\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from data_cleaning import *\n",
    "from geo_spatial import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f526e-3513-4c65-bb99-7666b35723c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cluster = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "114e1aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_sagemaker_notebook:\n",
    "    train_data = pd.read_parquet(f's3://think-tank-casestudy/features_engineered/n_cluster_{n_cluster}/feature_engineered_train.parquet')\n",
    "    test_data = pd.read_parquet(f's3://think-tank-casestudy/features_engineered/n_cluster_{n_cluster}/feature_engineered_test.parquet')\n",
    "else:\n",
    "    train_data = pd.read_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/train_data_encoded.csv', header=0,index_col=False)\n",
    "    test_data = pd.read_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/test_data_encoded.csv', header=0, index_col=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f5184",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multioutput NN model - 10 point sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80478b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['trip_id', 'sequence', 'final_point', 'polyline', 'n_coordinate_points', 'total_distance_km','total_flight_time_minutes']]\n",
    "test_data = test_data[['trip_id', 'sequence', 'final_point','polyline',  'n_coordinate_points', 'total_distance_km','total_flight_time_minutes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bafa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_polyline_to_geojson_format(data=train_data, name_column='polyline')\n",
    "test_data = convert_polyline_to_geojson_format(data=test_data, name_column='polyline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0989af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_fix_length_sequences(train_data, 10, start_sequence_column='start_point', stop_sequence_column='dest_point', sequence_column='sequence')\n",
    "test_data = create_fix_length_sequences(test_data, 10,start_sequence_column='start_point', stop_sequence_column='dest_point', sequence_column='sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0be5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_coordinates(coordinates):\n",
    "    return (coordinates[0] + 90)/ 180, (coordinates[1] + 180)/ 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02e26b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized_polyline'] = train_data['polyline']\\\n",
    ".apply(lambda trip: np.array(list(map(_normalize_coordinates,trip)))[0:10])\n",
    "\n",
    "test_data['normalized_polyline'] = test_data['polyline']\\\n",
    ".apply(lambda trip: np.array(list(map(_normalize_coordinates,trip)))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eaa1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['dest_point_lat_norm'] = train_data['final_point']\\\n",
    ".apply(lambda coordinates: _normalize_coordinates(convert_string_to_geojson(coordinates))[0]) \n",
    "train_data['dest_point_lon_norm'] = train_data['final_point']\\\n",
    ".apply(lambda coordinates: _normalize_coordinates(convert_string_to_geojson(coordinates))[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f339513",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['dest_point_lat_norm'] = test_data['final_point']\\\n",
    ".apply(lambda coordinates: _normalize_coordinates(convert_string_to_geojson(coordinates))[0]) \n",
    "test_data['dest_point_lon_norm'] = test_data['final_point']\\\n",
    ".apply(lambda coordinates: _normalize_coordinates(convert_string_to_geojson(coordinates))[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "493840cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [[0.45211864999999996, 0.6142817], [0.45211945...\n",
       "1          [[0.45200085, 0.61433285], [0.4519980500000000...\n",
       "2          [[0.45215019999999995, 0.6142787749999999], [0...\n",
       "3          [[0.45236289999999996, 0.614310975], [0.452362...\n",
       "4          [[0.4519667, 0.61439025], [0.45196695, 0.61439...\n",
       "                                 ...                        \n",
       "1366757    [[0.45230165, 0.614301575], [0.45230145, 0.614...\n",
       "1366758    [[0.45215295, 0.6142945], [0.45215285, 0.61429...\n",
       "1366759    [[0.45216589999999995, 0.6142801250000001], [0...\n",
       "1366760    [[0.4520516, 0.614319125], [0.4520515, 0.61431...\n",
       "1366761    [[0.4521359, 0.6142795249999999], [0.45213655,...\n",
       "Name: normalized_polyline, Length: 1366762, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.normalized_polyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f74239b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Q619505/miniconda3/envs/py3.11/lib/python3.11/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "X_train.normalized_polyline = X_train.normalized_polyline.apply(lambda sequence : sequence.reshape((1,10,2)))\n",
    "X_test.normalized_polyline = X_test.normalized_polyline.apply(lambda sequence : sequence.reshape((1,10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52e317e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1366762,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.normalized_polyline.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdf052fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data[['normalized_polyline']]\n",
    "X_test = test_data[['normalized_polyline']]\n",
    "y_train = train_data[['dest_point_lat_norm', 'dest_point_lon_norm']]\n",
    "y_test =  test_data[['dest_point_lat_norm', 'dest_point_lon_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cd96062",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/X_train.csv', header=True, index=False)\n",
    "X_test.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/X_test.csv', header=True, index=False)\n",
    "y_train.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/y_train.csv', header=True, index=False)\n",
    "y_test.to_csv(f'{prefix}/ml-project-taxi-prediction/data/processed/y_test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3ebe9-34a1-4cd5-9915-feaa7bba93dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1a) Random Forest - Multiclass - Fix sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbcd855d-4f06-455f-a095-a58a07f1546d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_feature_columns_config_1_list = ['TRIP_ID', 'TOTAL_DISTANCE_KM', 'TOTAL_FLIGHT_TIME_MINUTES', 'CENTER_LON', 'CENTER_LAT', 'index',\n",
    "'START_POINT_LON', 'START_POINT_LAT', 'DEST_POINT_LON', 'DEST_POINT_LAT', 'START_SEQUENCE', 'STOP_SEQUENCE', 'CLUSTER_LABEL', 'SEQUENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6487cf91-3089-42e6-bad1-030f5c472a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = create_fix_length_sequences(train_data, 10)\n",
    "test_data = create_fix_length_sequences(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f61f22-6720-4ac6-9624-bf46b7b7baf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_config_1 = [column_ for column_ in train_data.columns if not column_ in non_feature_columns_config_1_list]\n",
    "label_config_1 = ['DEST_POINT_LON', 'DEST_POINT_LAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73646310-f769-4cdb-8999-d471e8f16e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_reduced = train_data.sample(300000, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f1d23c-eb6c-4ec2-922e-5f04af5f8a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_data_reduced[features_config_1].to_numpy()\n",
    "y_train = train_data_reduced[label_config_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e953012-b6ec-4b33-aace-39531a90653f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test_data[features_config_1].to_numpy()\n",
    "y_test = test_data[label_config_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee78996-2bc1-472f-b6c2-e8f56d938e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_sequence_train = pd.DataFrame(train_data_reduced.START_SEQUENCE.tolist()).to_numpy()\n",
    "stop_sequence_train = pd.DataFrame(train_data_reduced.STOP_SEQUENCE.tolist()).to_numpy()\n",
    "\n",
    "start_sequence_test = pd.DataFrame(test_data.START_SEQUENCE.tolist()).to_numpy()\n",
    "stop_sequence_test = pd.DataFrame(test_data.STOP_SEQUENCE.tolist()).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661fd6aa-92e9-4101-9bc9-f66ca20035cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, start_sequence_train, stop_sequence_train), axis=1).astype(float)\n",
    "X_test = np.concatenate((X_test, start_sequence_test, stop_sequence_test), axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f93a8f5-e646-429f-a0ec-ada09abf67de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(X_train.shape[1] == X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd68704-4f76-4667-be3e-16592432f566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_leaf=0.05, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_leaf=0.05, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=0.05, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(min_samples_leaf=0.05, random_state=0)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "916664ce-63bc-4c01-93a4-46d7e46e6ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d82384df-07ad-49ba-b189-5c718162b3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(y_pred, columns = ['LON','LAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb8e55da-f50e-4cb1-85af-4a777d3dca84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.concat([y_test, df_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b772eb-935e-4fb2-b059-5213a98f5ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred['h_distance'] = df_pred.apply(lambda row: haversine_distance(lat1=row.DEST_POINT_LAT,\n",
    "                                                                     lat2=row.LAT,\n",
    "                                                                     lon1=row.DEST_POINT_LON,\n",
    "                                                                     lon2=row.LON), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12438f28-1223-4730-90a6-cc8903e97d09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    269.000000\n",
       "mean       2.103287\n",
       "std        7.648067\n",
       "min        0.036385\n",
       "25%        0.667274\n",
       "50%        1.035733\n",
       "75%        1.487928\n",
       "max      114.168664\n",
       "Name: h_distance, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.h_distance.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c73b4-46e1-4d9e-9940-1e33ac128972",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1b) Random Forest - Multiclass - Variable sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8e6a8-831c-4268-a6a0-2815bfeebb97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  2) NN with LSTM - full sequence only - no tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b39ef-c481-45f3-9160-4af8102be36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_config = ['SEQUENCE']\n",
    "label_config = ['CLUSTER_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e907fb3-100d-47d3-99c5-0f0c5eecc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features_config]\n",
    "y_train = train_data[label_config]\n",
    "X_test = test_data[features_config]\n",
    "y_test = test_data[label_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc02f6-0ecd-4ded-869e-17bab9da2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max length of sequence\n",
    "if train_data.N_COORDINATE_POINTS.max() > test_data.N_COORDINATE_POINTS.max():\n",
    "    max_sequence= train_data.N_COORDINATE_POINTS.max()\n",
    "else:\n",
    "    max_sequence = test_data.N_COORDINATE_POINTS.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece5360-56cc-49c5-97a2-0de836ce2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_shape(sequence_,max_sequence):\n",
    "    sequence_array = np.array(sequence_)\n",
    "    zeros_ = np.zeros(2*max_sequence-len(sequence_array))\n",
    "    return np.append(sequence_array,zeros_).reshape(1,max_sequence,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fa859-54da-409a-889a-ea4eecf6a292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test['SEQUENCE'] = X_test.SEQUENCE.apply(lambda sequence_: create_lstm_shape(sequence_,max_sequence))\n",
    "X_train['SEQUENCE'] = X_train.SEQUENCE.apply(lambda sequence_: create_lstm_shape(sequence_,max_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dce20-d663-4821-ad20-9c9f0e6ec923",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(tensorflow.compat.v1.keras.layers.CuDNNLSTM(200, input_shape=(612,2)))\n",
    "lstm_model.add(Dense(4000, activation='softmax'))\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b439-607a-461b-a12f-11decbc168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4b30a-7929-481a-947b-cb20a54e903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(val) for val in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec961991-7a91-4f03-b106-d55d342e6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f0223-1caf-4d94-b4e4-21975968948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=lstm_model.fit(X_train,\n",
    "                       y_train.astype(np.float32), \n",
    "                       validation_split=0.2, epochs=100, batch_size=448, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27883522-2fa2-4924-bf41-dac665dee861",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2b) NN - fixed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db987f6c-af33-4144-866f-a5a0e05cf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence_train_start = pd.DataFrame(train_data.START_SEQUENCE.tolist()).fillna(2000)\n",
    "df_sequence_train_stop = pd.DataFrame(train_data.STOP_SEQUENCE.tolist()).fillna(2000)\n",
    "\n",
    "df_sequence_test_start = pd.DataFrame(test_data.START_SEQUENCE.tolist()).fillna(2000)\n",
    "df_sequence_test_stop = pd.DataFrame(test_data.STOP_SEQUENCE.tolist()).fillna(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57a08f-482d-4462-b54a-ea9b04d951b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence_train_start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d78a6-9713-4978-a66f-fd4cbdddfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nas with arbitrary large number to mask later\n",
    "#df_sequence_train = pd.DataFrame(train_data.SEQUENCE.tolist()).fillna(2000).to_numpy()\n",
    "#df_sequence_test = pd.DataFrame(test_data.SEQUENCE.tolist()).fillna(2000).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041f019-4c99-4a24-bca9-4280d155ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_config_2 = ['N_COORDINATE_POINTS','TOTAL_DISTANCE_KM','2013_10',\n",
    "       '2013_11', '2013_12', '2013_7', '2013_8', '2013_9', '2014_1', '2014_2',\n",
    "       '2014_3', '2014_4', '2014_5', '2014_6', '2014_7', '10.0', '12.0',\n",
    "       '13.0', '14.0', '15.0', '18.0', '20.0', '21.0', '23.0', '25.0', '26.0',\n",
    "       '27.0', '28.0', '33.0', '34.0', '35.0', '36.0', '38.0', '40.0', '42.0',\n",
    "       '52.0', '53.0', '54.0', '56.0', '57.0', '58.0', '6.0', '60.0', '61.0',\n",
    "       '63.0', '7.0', '9.0', 'OTHER', 'Cloudy', 'Foggy', 'Rainy', 'Sunny',\n",
    "       'Windy', 'A', 'B', 'C', '16.0', '2014_10', '2014_11', '2014_12',\n",
    "       '2014_8', '2014_9', '47.0', '49.0']\n",
    "label_config_2 = ['CLUSTER_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61eacd8-8e93-4a75-8a9e-6498d2c83f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features_config_2].astype(float)\n",
    "X_test = test_data[features_config_2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82553ba-48f3-46a7-99f7-4778a87b4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([df_sequence_train_start,df_sequence_train_stop, X_train], axis=1)\n",
    "X_test = pd.concat([df_sequence_test_start,df_sequence_test_stop, X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24874745-e6a0-4e83-a8ad-461afbe78a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[label_config_2]\n",
    "y_test =  test_data[label_config_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0ce96-357a-4472-ade7-dfeab32e4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1])))\n",
    "model.add(tensorflow.keras.layers.Masking(mask_value=2000))\n",
    "model.add(LSTM(200, activation='relu'))\n",
    "model.add(Dense(4000, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['AUC'])\n",
    "          \n",
    "#X_pred_train = model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d6765-a402-4631-b1ef-6ecb8ce893a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
